import type { CapacityRequest } from './types';

export const mockRequests: CapacityRequest[] = [
  {
    id: 'req-1',
    requesterName: 'Livepeer Studio - AI Video Team',
    requesterAccount: '0x7a3b...f29c',
    gpuModel: 'RTX 4090',
    vram: 24,
    osVersion: 'Ubuntu 22.04',
    cudaVersion: '12.2',
    count: 10,
    pipeline: 'text-to-image',
    startDate: '2026-02-15',
    endDate: '2026-04-15',
    validUntil: '2026-02-28',
    hourlyRate: 1.20,
    reason: 'Scaling Flux.1 model inference to meet growing demand for high-quality text-to-image generation. We expect a 3x traffic increase in Q1.',
    riskLevel: 5,
    softCommits: [
      { id: 'sc-1', userId: 'u-1', userName: 'NodeRunner Pro', timestamp: '2026-01-20T10:00:00Z' },
      { id: 'sc-2', userId: 'u-2', userName: 'GPU Capital', timestamp: '2026-01-21T14:30:00Z' },
      { id: 'sc-3', userId: 'u-3', userName: 'Decentralized Compute Co', timestamp: '2026-01-22T09:15:00Z' },
      { id: 'sc-4', userId: 'u-4', userName: 'HashPower Labs', timestamp: '2026-01-23T16:00:00Z' },
      { id: 'sc-5', userId: 'u-5', userName: 'CloudNodes.io', timestamp: '2026-01-24T11:45:00Z' },
      { id: 'sc-6', userId: 'u-6', userName: 'InferenceNet', timestamp: '2026-01-25T08:20:00Z' },
    ],
    comments: [
      { id: 'c-1', author: 'NodeRunner Pro', text: 'We have 4x RTX 4090 ready to deploy. What SLA do you expect?', timestamp: '2026-01-20T10:05:00Z' },
      { id: 'c-2', author: 'Livepeer Studio', text: 'Looking for 99.5% uptime with sub-2s latency for image generation.', timestamp: '2026-01-20T12:00:00Z' },
      { id: 'c-3', author: 'GPU Capital', text: 'Can provide 6 units. Is there flexibility on the CUDA version?', timestamp: '2026-01-21T14:35:00Z' },
    ],
    createdAt: '2026-01-15T08:00:00Z',
    status: 'active',
  },
  {
    id: 'req-2',
    requesterName: 'Decentralized AI Labs - LLM Division',
    requesterAccount: '0x3f91...a84e',
    gpuModel: 'A100 80GB',
    vram: 80,
    osVersion: 'Ubuntu 22.04',
    cudaVersion: '12.1',
    count: 5,
    pipeline: 'llm',
    startDate: '2026-03-01',
    endDate: '2026-06-01',
    validUntil: '2026-02-20',
    hourlyRate: 2.50,
    reason: 'Deploying Llama-3 70B for inference at scale. Need high-VRAM GPUs for full model weight loading without quantization.',
    riskLevel: 4,
    softCommits: [
      { id: 'sc-7', userId: 'u-7', userName: 'DataCenter One', timestamp: '2026-01-18T09:00:00Z' },
      { id: 'sc-8', userId: 'u-8', userName: 'AI Compute Pool', timestamp: '2026-01-19T15:00:00Z' },
    ],
    comments: [
      { id: 'c-4', author: 'DataCenter One', text: 'We can offer A100 80GB with NVLink. Interested in long-term contract?', timestamp: '2026-01-18T09:10:00Z' },
    ],
    createdAt: '2026-01-12T14:00:00Z',
    status: 'active',
  },
  {
    id: 'req-3',
    requesterName: 'Render Core - Video Pipeline',
    requesterAccount: '0x8bc2...d71f',
    gpuModel: 'H100',
    vram: 80,
    osVersion: 'Ubuntu 24.04',
    cudaVersion: '12.4',
    count: 3,
    pipeline: 'segment-anything-2',
    startDate: '2026-03-15',
    endDate: '2026-05-15',
    validUntil: '2026-03-01',
    hourlyRate: 3.80,
    reason: 'SAM2 workload requires top-tier GPUs. Building real-time video segmentation pipeline for broadcast partners.',
    riskLevel: 3,
    softCommits: [],
    comments: [],
    createdAt: '2026-01-10T11:00:00Z',
    status: 'active',
  },
  {
    id: 'req-4',
    requesterName: 'StreamVision AI',
    requesterAccount: '0x5d4a...e38b',
    gpuModel: 'RTX 4090',
    vram: 24,
    osVersion: 'Ubuntu 22.04',
    cudaVersion: '12.2',
    count: 8,
    pipeline: 'live-video-to-video',
    startDate: '2026-02-20',
    endDate: '2026-05-20',
    validUntil: '2026-02-15',
    hourlyRate: 1.50,
    reason: 'Live streaming AI effects for gaming tournaments. Need reliable, low-latency GPU access for real-time style transfer.',
    riskLevel: 4,
    softCommits: [
      { id: 'sc-9', userId: 'u-9', userName: 'GameNodes', timestamp: '2026-01-16T13:00:00Z' },
      { id: 'sc-10', userId: 'u-1', userName: 'NodeRunner Pro', timestamp: '2026-01-17T10:00:00Z' },
      { id: 'sc-11', userId: 'u-10', userName: 'PixelForge', timestamp: '2026-01-18T16:30:00Z' },
    ],
    comments: [
      { id: 'c-5', author: 'GameNodes', text: 'Perfect for our gaming cluster. Can dedicate 3 units.', timestamp: '2026-01-16T13:05:00Z' },
    ],
    createdAt: '2026-01-14T09:00:00Z',
    status: 'active',
  },
  {
    id: 'req-5',
    requesterName: 'Livepeer Studio - AI Video Team',
    requesterAccount: '0x7a3b...f29c',
    gpuModel: 'A100 40GB',
    vram: 40,
    osVersion: 'Ubuntu 22.04',
    cudaVersion: '12.1',
    count: 6,
    pipeline: 'image-to-video',
    startDate: '2026-03-01',
    endDate: '2026-06-30',
    validUntil: '2026-02-25',
    hourlyRate: 2.00,
    reason: 'Expanding image-to-video pipeline capacity for Stable Video Diffusion. Growing enterprise demand.',
    riskLevel: 5,
    softCommits: [
      { id: 'sc-12', userId: 'u-2', userName: 'GPU Capital', timestamp: '2026-01-20T08:00:00Z' },
      { id: 'sc-13', userId: 'u-7', userName: 'DataCenter One', timestamp: '2026-01-21T11:00:00Z' },
      { id: 'sc-14', userId: 'u-11', userName: 'ComputeHive', timestamp: '2026-01-22T14:00:00Z' },
      { id: 'sc-15', userId: 'u-12', userName: 'NeuralOps', timestamp: '2026-01-23T09:00:00Z' },
    ],
    comments: [
      { id: 'c-6', author: 'GPU Capital', text: 'We have A100 40GB available. Are you open to A100 80GB at slightly higher rate?', timestamp: '2026-01-20T08:10:00Z' },
      { id: 'c-7', author: 'Livepeer Studio', text: 'Yes, 80GB would work too. Please share your pricing.', timestamp: '2026-01-20T10:30:00Z' },
    ],
    createdAt: '2026-01-18T10:00:00Z',
    status: 'active',
  },
  {
    id: 'req-6',
    requesterName: 'VoiceAI Solutions',
    requesterAccount: '0x2e7c...b56d',
    gpuModel: 'RTX 3090',
    vram: 24,
    osVersion: 'Ubuntu 20.04',
    cudaVersion: '11.8',
    count: 4,
    pipeline: 'audio-to-text',
    startDate: '2026-02-10',
    endDate: '2026-04-10',
    validUntil: '2026-02-08',
    hourlyRate: 0.80,
    reason: 'Whisper large-v3 transcription service expansion for healthcare compliance recordings.',
    riskLevel: 2,
    softCommits: [
      { id: 'sc-16', userId: 'u-13', userName: 'MedTech Nodes', timestamp: '2026-01-25T10:00:00Z' },
    ],
    comments: [],
    createdAt: '2026-01-22T16:00:00Z',
    status: 'active',
  },
  {
    id: 'req-7',
    requesterName: 'PixelCraft Studio',
    requesterAccount: '0x9a1d...c43e',
    gpuModel: 'RTX 4080',
    vram: 16,
    osVersion: 'Ubuntu 22.04',
    cudaVersion: '12.3',
    count: 12,
    pipeline: 'text-to-image',
    startDate: '2026-02-01',
    endDate: '2026-03-31',
    validUntil: '2026-02-10',
    hourlyRate: 0.95,
    reason: 'High-volume SDXL generation for our creative marketplace. Need cost-effective GPUs with decent VRAM.',
    riskLevel: 3,
    softCommits: [
      { id: 'sc-17', userId: 'u-1', userName: 'NodeRunner Pro', timestamp: '2026-01-26T09:00:00Z' },
      { id: 'sc-18', userId: 'u-14', userName: 'EcoCompute', timestamp: '2026-01-27T14:00:00Z' },
    ],
    comments: [
      { id: 'c-8', author: 'EcoCompute', text: 'Can provide 5 units with green energy. Interested?', timestamp: '2026-01-27T14:05:00Z' },
    ],
    createdAt: '2026-01-24T12:00:00Z',
    status: 'active',
  },
  {
    id: 'req-8',
    requesterName: 'Neural Bridge Research',
    requesterAccount: '0x4f8e...a92c',
    gpuModel: 'H200',
    vram: 80,
    osVersion: 'Ubuntu 24.04',
    cudaVersion: '12.5',
    count: 2,
    pipeline: 'llm',
    startDate: '2026-04-01',
    endDate: '2026-09-30',
    validUntil: '2026-03-15',
    hourlyRate: 5.00,
    reason: 'Fine-tuning and serving a custom 100B+ parameter model for scientific research. Cutting-edge hardware required.',
    riskLevel: 2,
    softCommits: [],
    comments: [
      { id: 'c-9', author: 'DataCenter One', text: 'H200 availability is limited. We may have 1 unit by April.', timestamp: '2026-01-28T09:00:00Z' },
    ],
    createdAt: '2026-01-26T15:00:00Z',
    status: 'active',
  },
];
